{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraper for Wikipedia \n",
    "\n",
    "We will be scraping information about Finnish athletes who have medaled at the Summer Olympics. For more information about scraping, consult the documentation for Beautiful Soup at https://www.crummy.com/software/BeautifulSoup/bs4/doc/. \n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading one web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the site we want to scrape\n",
    "url = \"https://en.wikipedia.org/wiki/Mira_Potkonen\"\n",
    "\n",
    "# we ask the server for the webpage\n",
    "r = requests.get(url)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status code tells us about the server's response\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the webpage -- like if you clicked \"View Source\" in a broswer\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = r.content\n",
    "\n",
    "#parse page with bs4\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it look a little nicer\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects the title element of this HTML page (<title>)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects the text content of the title element of this HTML page\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects the first HTML large heading element (<h1>)\n",
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects all the hyperlinks on the page (<a>)\n",
    "soup.findAll('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write some code that selects the first table (<table>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write some code that selects all the items in lists on the page <li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write some code that selects the text within the first paragraph (<p>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Challenge] Go on a point-and-click adventure with the Developer Tools on your browser and try to select the text of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write some code that selects the text of your choice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading multiple web pages\n",
    "- First, we'll grab all the URLs to medalist Wikipedia pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Finland_at_the_Olympics\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = r.content\n",
    "\n",
    "#parse page with bs4\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we are interested in a tabls\n",
    "tables = soup.findAll('table')\n",
    "\n",
    "#the 9th table on the page contains Summer Olympic medalists\n",
    "table = tables[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just the rows in the table\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# the first row contains the table header\n",
    "rows[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the cells in last row in the table\n",
    "cells = rows[-1].find_all('td')\n",
    "\n",
    "# select the second cell in that row\n",
    "cells[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_to_athletes = []\n",
    "\n",
    "# loop through all the rows in the table\n",
    "for row in rows:\n",
    "    # break down each row into cells\n",
    "    cells = row.find_all('td')\n",
    "    # check if there more than one cell\n",
    "    if len(cells) > 1:\n",
    "        # check if the second cell (corresponding to the name column) contains a hyperlink\n",
    "        if (cells[1].find('a')):\n",
    "            # if the cell contains a hyperlink, get the link referenced\n",
    "            link_to_athlete = cells[1].find('a')['href']\n",
    "            # add the link referenced to a list\n",
    "            links_to_athletes.append(link_to_athlete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_to_athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get full urls, add the base part of the URL to each\n",
    "links_to_athletes = ['https://en.wikipedia.org' + i for i in links_to_athletes]\n",
    "links_to_athletes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we'll visit each of the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# loop through all of the links\n",
    "for athlete_page in links_to_athletes:\n",
    "    \n",
    "    # request the athlete's wiki page\n",
    "    r = requests.get(athlete_page)\n",
    "    page = r.content\n",
    "    \n",
    "    # parse page with bs4\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    # this selects the first HTML element span (<span>) that has the class attribute \"birthplace\"\n",
    "    birthplace = soup.find(\"span\", {\"class\": \"birthplace\"})\n",
    "    \n",
    "    # check to see if birthplace was found\n",
    "    if birthplace:\n",
    "        # add name and birthplace of athlete to an object\n",
    "        athlete_info = {}\n",
    "        athlete_info['name'] = soup.find('h1').text\n",
    "        athlete_info['birthplace'] = birthplace.text\n",
    "        # add that object to our data variable\n",
    "        data.append(athlete_info)\n",
    "    \n",
    "    # be kind to Wikipedia and take a break between scrapes\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check this data out in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert our findings to a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can select rows that contain athletes born in Helsinki\n",
    "\n",
    "df[df.birthplace==\"Helsinki, Finland\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the row that contains our pal Mira\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
